---
title: Spark
---
## Spark

This is a stub. <a href='https://github.com/freecodecamp/guides/tree/master/src/pages/data-science-tools/spark/index.md' target='_blank' rel='nofollow'>Help our community expand it</a>.

<a href='https://github.com/freecodecamp/guides/blob/master/README.md' target='_blank' rel='nofollow'>This quick style guide will help ensure your pull request gets accepted</a>.

<!-- The article goes here, in GitHub-flavored Markdown. Feel free to add YouTube videos, images, and CodePen/JSBin embeds  -->

#### More Information:
<!-- Please add any articles you think might be helpful to read before writing the article -->

Apache Spark is a speedy cluster based general purpose computing platform for large scale data (Big Data) processing requirements. It is quicker than comparative solutions like Hadoop and it utilises computing resources more efficiently. Spark performs very well with both batch and real-time based interative data processign tasks.

The core components of the Apache Spark framework are Spark SQL, Spark Streaming, MLlib (machine learning library) and GraphX (graph). It is built with the Scala programming language. It has high-level APIs to support Scala, Java, Python and R.

Key Spark constructs include the following:
1. RDD - Resilient Distributed Dataset
2. DAG - Direct Acyclic Graph
3. Sparkcontext
4. Transformations
5. Actions

